{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25c5a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssit5\\AppData\\Local\\Temp\\ipykernel_4132\\2871647109.py:40: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  trnMat = pickle.load(fs)# (pickle.load(fs) != 0).astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from scipy.sparse import csr_matrix\n",
    "class Args:\n",
    "\tdata = 'amazon'\n",
    "\tpercent = 0\n",
    "\tgraphSampleN = 15000\n",
    "\tbatch = 512\n",
    "\tgraphNum = 5\n",
    "\tkeepRate = 0.5\n",
    "\ttestSize = 1000\n",
    "\ttest = True\n",
    "\tpos_length = 200\n",
    "\tsslNum = 80\n",
    "args = Args()\n",
    "class DataHandler:\n",
    "\tdef __init__(self):\n",
    "\t\tif args.data == 'yelp':\n",
    "\t\t\tpredir = './Datasets/Yelp/'\n",
    "\t\telif args.data == 'gowalla':\n",
    "\t\t\tpredir = './Datasets/gowalla/'\n",
    "\t\telif args.data == 'amazon':\n",
    "\t\t\tpredir = './Datasets/amazon/'\n",
    "\t\telse:\n",
    "\t\t\tpredir='./Datasets/'+args.data+'/'\n",
    "\t\tpredir = predir\n",
    "\t\tself.trnfile = predir + 'trn_mat_time'\n",
    "\t\tself.tstfile = predir + 'tst_int'\n",
    "\t\tself.sequencefile=predir+'sequence'\n",
    "\t\tself.test_dictfile=predir+'test_dict'\n",
    "\tdef LoadData(self):\n",
    "\t\tif args.percent > 1e-8:\n",
    "\t\t\tprint('noised')\n",
    "\t\t\twith open(self.predir + 'noise_%.2f' % args.percent, 'rb') as fs:\n",
    "\t\t\t\ttrnMat = pickle.load(fs)\n",
    "\t\telse:\n",
    "\t\t\twith open(self.trnfile, 'rb') as fs:\n",
    "\t\t\t\t# print(pickle.load(fs))\n",
    "\t\t\t\ttrnMat = pickle.load(fs)# (pickle.load(fs) != 0).astype(np.float32)\n",
    "\t\t# test set\n",
    "\t\twith open(self.tstfile, 'rb') as fs:\n",
    "\t\t\ttstInt = np.array(pickle.load(fs))\n",
    "\t\twith open(self.sequencefile, 'rb') as fs:\n",
    "\t\t\tself.sequence = pickle.load(fs)\n",
    "\t\tif os.path.isfile(self.test_dictfile):\n",
    "\t\t\twith open(self.test_dictfile, 'rb') as fs:\n",
    "\t\t\t\tself.test_dict = pickle.load(fs)\n",
    "\t\t# print(\"tstInt\",tstInt)\n",
    "\t\ttstStat = (tstInt != None)\n",
    "\t\t# print(\"tstStat\",tstStat,len(tstStat))\n",
    "\t\ttstUsrs = np.reshape(np.argwhere(tstStat != False), [-1])\n",
    "\t\t# print(\"tstUsrs\",tstUsrs,len(tstUsrs))\n",
    "\t\t# self.trnMat = trnMat[0]\n",
    "\t\tdef generate_rating_matrix_test(user_seq, num_users, num_items):\n",
    "\t\t\t# three lists are used to construct sparse matrix\n",
    "\t\t\trow = []\n",
    "\t\t\tcol = []\n",
    "\t\t\tdata = []\n",
    "\t\t\tfor user_id, item_list in enumerate(user_seq):\n",
    "\t\t\t\tfor item in item_list:  #\n",
    "\t\t\t\t\trow.append(user_id)\n",
    "\t\t\t\t\tcol.append(item)\n",
    "\t\t\t\t\tdata.append(1)\n",
    "\n",
    "\t\t\trow = np.array(row)\n",
    "\t\t\tcol = np.array(col)\n",
    "\t\t\tdata = np.array(data)\n",
    "\t\t\trating_matrix = csr_matrix((data, (row, col)), shape=(num_users, num_items))\n",
    "\n",
    "\t\t\treturn rating_matrix\n",
    "\t\targs.user, args.item = trnMat[0].shape\n",
    "\t\tself.trnMat=generate_rating_matrix_test(self.sequence,args.user, args.item)\n",
    "\t\tself.subMat = trnMat[1]\n",
    "\t\tself.timeMat = trnMat[2]\n",
    "\t\t# print(\"trnMat\",trnMat[0],trnMat[1],trnMat[2])\n",
    "\t\tself.tstInt = tstInt\n",
    "\t\tself.tstUsrs = tstUsrs\n",
    "\t\tself.prepareGlobalData()\n",
    "\n",
    "\tdef prepareGlobalData(self):\n",
    "\t\t# adj = self.subMat\n",
    "\t\tself.maxTime=1\n",
    "\t\t# self.subMat,self.maxTime=self.timeProcess(self.subMat)\n",
    "\t\t# print(self.subMat[0],self.subMat[-1])\n",
    "\n",
    "\t\tself.item_with_pop=[]\n",
    "\t\n",
    "handler = DataHandler()\n",
    "handler.LoadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61d45dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def filter_by_popularity(popular_percentage):\n",
    "    item_interactions = Counter()\n",
    "    user_interactions = Counter()\n",
    "    for user_id, item_list in enumerate(handler.sequence):\n",
    "        if user_id not in handler.tstUsrs:\n",
    "            continue\n",
    "        item_interactions.update(item_list)\n",
    "        user_interactions[user_id] += len(item_list)\n",
    "    items_cutoff = int(len(item_interactions) * popular_percentage)\n",
    "    users_cutoff = int(len(user_interactions) * popular_percentage)\n",
    "    sorted_items = sorted(item_interactions.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_users = sorted(user_interactions.items(), key=lambda x: x[1], reverse=True)\n",
    "    popular_items = sorted([item for item, _ in sorted_items[:items_cutoff]])\n",
    "    unpopular_items = sorted([item for item, _ in sorted_items[items_cutoff:]])\n",
    "    popular_users = sorted([user for user, _ in sorted_users[:users_cutoff]])\n",
    "    unpopular_users = sorted([user for user, _ in sorted_users[users_cutoff:]])\n",
    "    # Convert to numpy arrays\n",
    "    popular_items = np.array(popular_items, dtype=np.int32)\n",
    "    unpopular_items = np.array(unpopular_items, dtype=np.int32)\n",
    "    popular_users = np.array(popular_users, dtype=np.int32)\n",
    "    unpopular_users = np.array(unpopular_users, dtype=np.int32)\n",
    "    return popular_items, unpopular_items, popular_users, unpopular_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "038da463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(handler.sequence)\n",
    "# handler.sequence[0]\n",
    "# sorted_ids = np.argsort(handler.tstInt)\n",
    "# sorted_ids\n",
    "# for x in handler.tstInt:\n",
    "#     if x is not None:\n",
    "#         print(x)\n",
    "len(handler.subMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b134be3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<11199x30821 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 72280 stored elements in Compressed Sparse Row format>, <11199x30821 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 78997 stored elements in Compressed Sparse Row format>, <11199x30821 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 79692 stored elements in Compressed Sparse Row format>, <11199x30821 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 78096 stored elements in Compressed Sparse Row format>, <11199x30821 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 45651 stored elements in Compressed Sparse Row format>]\n",
      "[<11199x30821 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 72280 stored elements in Compressed Sparse Row format>, <11199x30821 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 78997 stored elements in Compressed Sparse Row format>, <11199x30821 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 79692 stored elements in Compressed Sparse Row format>, <11199x30821 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 78096 stored elements in Compressed Sparse Row format>, <11199x30821 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 45651 stored elements in Compressed Sparse Row format>]\n"
     ]
    }
   ],
   "source": [
    "def sampleTestBatch(batIds, labelMat): # labelMat=TrainMat(adj)\n",
    "    batch = len(batIds)\n",
    "    temTst = handler.tstInt[batIds]\n",
    "    temLabel = labelMat[batIds].toarray()\n",
    "    temlen = batch * args.testSize# args.item\n",
    "    uLocs = [None] * temlen\n",
    "    iLocs = [None] * temlen\n",
    "    uLocs_seq = [None] * temlen\n",
    "    tstLocs = [None] * batch\n",
    "    sequence = [None] * args.batch\n",
    "    mask = [None]*args.batch\n",
    "    cur = 0\n",
    "    val_list=[None]*args.batch\n",
    "    for i in range(batch):\n",
    "        if(args.test==True):\n",
    "            posloc = temTst[i]\n",
    "        else:\n",
    "            posloc = handler.sequence[batIds[i]][-1]\n",
    "            val_list[i]=posloc\n",
    "        rdnNegSet = np.array(handler.test_dict[batIds[i]+1][:args.testSize-1])-1\n",
    "        locset = np.concatenate((rdnNegSet, np.array([posloc])))\n",
    "        tstLocs[i] = locset\n",
    "        for j in range(len(locset)):\n",
    "            uLocs[cur] = batIds[i]\n",
    "            iLocs[cur] = locset[j]\n",
    "            uLocs_seq[cur] = i\n",
    "            cur += 1\n",
    "        sequence[i]=np.zeros(args.pos_length,dtype=int)\n",
    "        mask[i]=np.zeros(args.pos_length)\n",
    "        if(args.test==True):\n",
    "            posset=handler.sequence[batIds[i]]\n",
    "        else:\n",
    "            posset=handler.sequence[batIds[i]][:-1]\n",
    "        # posset=handler.sequence[batIds[i]]\n",
    "        if(len(posset)<=args.pos_length):\n",
    "            sequence[i][-len(posset):]=posset\n",
    "            mask[i][-len(posset):]=1\n",
    "        else:\n",
    "            sequence[i]=posset[-args.pos_length:]\n",
    "            mask[i]+=1\n",
    "    if(batch<args.batch):\n",
    "        for i in range(batch,args.batch):\n",
    "            sequence[i]=np.zeros(args.pos_length,dtype=int)\n",
    "            mask[i]=np.zeros(args.pos_length)\n",
    "    return uLocs, iLocs, temTst, tstLocs, sequence, mask, uLocs_seq, val_list\n",
    "\n",
    "def sampleSslBatch(batIds, labelMat, use_epsilon=True):\n",
    "    temLabel=list()\n",
    "    for k in range(args.graphNum):\n",
    "        temLabel.append(labelMat[k][batIds].toarray())\n",
    "    batch = len(batIds)\n",
    "    temlen = batch * 2 * args.sslNum\n",
    "    uLocs = [[None] * temlen] * args.graphNum\n",
    "    iLocs = [[None] * temlen] * args.graphNum\n",
    "    uLocs_seq = [[None] * temlen] * args.graphNum\n",
    "    # epsilon=[[None] * temlen] * args.graphNum\n",
    "    for k in range(args.graphNum):\t\n",
    "        cur = 0\t\t\t\t\n",
    "        for i in range(batch):\n",
    "            posset = np.reshape(np.argwhere(temLabel[k][i]!=0), [-1])\n",
    "            # print(posset)\n",
    "            sslNum = min(args.sslNum, len(posset)//2)# len(posset)//4# \n",
    "            if sslNum == 0:\n",
    "                poslocs = [np.random.choice(args.item)]\n",
    "                neglocs = [poslocs[0]]\n",
    "            else:\n",
    "                all = np.random.choice(posset, sslNum*2) #- args.user\n",
    "                # print(all)\n",
    "                poslocs = all[:sslNum]\n",
    "                neglocs = all[sslNum:]\n",
    "            for j in range(sslNum):\n",
    "                posloc = poslocs[j]\n",
    "                negloc = neglocs[j]\t\t\t\n",
    "                uLocs[k][cur] = uLocs[k][cur+1] = batIds[i]\n",
    "                uLocs_seq[k][cur] = uLocs_seq[k][cur+1] = i\n",
    "                iLocs[k][cur] = posloc\n",
    "                iLocs[k][cur+1] = negloc\n",
    "                cur += 2\n",
    "        uLocs[k]=uLocs[k][:cur]\n",
    "        iLocs[k]=iLocs[k][:cur]\n",
    "        uLocs_seq[k]=uLocs_seq[k][:cur]\n",
    "    return uLocs, iLocs, uLocs_seq\n",
    "\n",
    "def testEpoch(popularity_users=None, popularity_items=None):\n",
    "    def generate_rating_matrix_test(user_seq, num_users, num_items, items_to_keep=None):\n",
    "        # three lists are used to construct sparse matrix\n",
    "        row = []\n",
    "        col = []\n",
    "        data = []\n",
    "        included_users = set()\n",
    "        for user_id, item_list in enumerate(user_seq):\n",
    "            for item in item_list:\n",
    "                if items_to_keep is not None and item not in items_to_keep:\n",
    "                    continue\n",
    "                row.append(user_id)\n",
    "                included_users.add(user_id)\n",
    "                col.append(item)\n",
    "                data.append(1)\n",
    "        row = np.array(row)\n",
    "        col = np.array(col)\n",
    "        data = np.array(data)\n",
    "        rating_matrix = csr_matrix((data, (row, col)), shape=(num_users, num_items))\n",
    "        return rating_matrix, included_users\n",
    "    pi, ui, pu, uu = filter_by_popularity(0.1)\n",
    "    \n",
    "    ids = handler.tstUsrs\n",
    "    if popularity_users == True:\n",
    "        ids = pu\n",
    "    elif popularity_users == False:\n",
    "        ids = uu\n",
    "\n",
    "    trnMat = handler.trnMat\n",
    "    if popularity_items == True:\n",
    "        trnMat, included_users = generate_rating_matrix_test(handler.sequence, args.user, args.item, items_to_keep=pi)\n",
    "        induced_ids = []\n",
    "        for user_id in ids:\n",
    "            if user_id not in included_users:\n",
    "                continue\n",
    "            induced_ids.append(user_id)\n",
    "        ids = np.array(induced_ids, dtype=np.int32)\n",
    "    elif popularity_items == False:\n",
    "        trnMat, included_users = generate_rating_matrix_test(handler.sequence, args.user, args.item, items_to_keep=ui)\n",
    "        induced_ids = []\n",
    "        for user_id in ids:\n",
    "            if user_id not in included_users:\n",
    "                continue\n",
    "            induced_ids.append(user_id)\n",
    "        ids = np.array(induced_ids, dtype=np.int32)\n",
    "\n",
    "    num = len(ids)\n",
    "    tstBat = args.batch\n",
    "    steps = int(np.ceil(num / tstBat))\n",
    "    # np.random.seed(100)\n",
    "    for i in range(steps):\n",
    "        st = i * tstBat\n",
    "        ed = min((i+1) * tstBat, num)\n",
    "        batIds = ids[st: ed]\n",
    "        feed_dict = {}\n",
    "        # print(\"batIds\",batIds)\n",
    "        uLocs, iLocs, temTst, tstLocs, sequence, mask, uLocs_seq, val_list = sampleTestBatch(batIds, trnMat)\n",
    "        suLocs, siLocs, _ = sampleSslBatch(batIds, handler.subMat, False)\n",
    "        feed_dict[\"uids\"] = uLocs\n",
    "        feed_dict[\"iids\"] = iLocs\n",
    "        feed_dict[\"sequence\"] = sequence\n",
    "        feed_dict[\"mask\"] = mask\n",
    "        feed_dict[\"uLocs_seq\"] = uLocs_seq\n",
    "        # print(\"test\",uLocs_seq)\n",
    "        for k in range(args.graphNum):\n",
    "            feed_dict[f\"suids[{k}]\"] = suLocs[k]\n",
    "            feed_dict[f\"siids[{k}]\"] = siLocs[k]\n",
    "        print(handler.subMat)\n",
    "        break\n",
    "    # print(feed_dict)\n",
    "\n",
    "testEpoch(popularity_users=True)\n",
    "testEpoch(popularity_users=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61baf12d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
